{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8667eff2-7df3-412e-87d2-13ac0ec350f0",
   "metadata": {},
   "source": [
    "# Multidimensional data frames: Using PySpark with JSON data\n",
    "This chapter covers\n",
    "- Drawing parallels between JSON documents and Python data structures\n",
    "- Ingesting JSON data within a data frame\n",
    "- Representing hierarchical data in a data frame through complex column types\n",
    "- Reducing duplication and reliance on auxiliary tables with a document/hierarchical data model\n",
    "- Creating and unpacking data from complex data types"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6964d236-c8da-49f5-937d-4dca943dfcef",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Start a spark session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e484c4b-5911-4b2a-8ad6-24dd6645bb59",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "import pyspark.sql.functions as F\n",
    "import os\n",
    "\n",
    "# change the account name to your email account\n",
    "account='sli'\n",
    "\n",
    "# define a root path to access the data in the DataAnalysisWithPythonAndPySpark\n",
    "data_path='/net/clusterhn/home/'+account+'/isa460/data/'\n",
    "\n",
    "# check if the Spark session is active. If it is activate, close it\n",
    "\n",
    "try:\n",
    "    if spark:\n",
    "        spark.stop()\n",
    "except:\n",
    "    pass    \n",
    "\n",
    "spark = (SparkSession.builder.appName(\"Multidimensional Data Frame\")\n",
    "        .config(\"spark.port.maxRetries\", \"100\")\n",
    "        .getOrCreate())\n",
    "\n",
    "# confiture the log level (defaulty is WWARN)\n",
    "spark.sparkContext.setLogLevel('ERROR')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65f5473d-32ee-41f7-8b3a-a137ea0ed61b",
   "metadata": {},
   "source": [
    "![json data as a limited python dictionary](https://raw.githubusercontent.com/Suhong88/ISA460_Fall2023/main/images/Figure%206.1.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c23e91a8-e298-4b3f-831c-d45e27c59755",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# load a json documnet as dictionary in python\n",
    "import json                        \n",
    " \n",
    "sample_json = \"\"\"{\n",
    "  \"id\": 143,\n",
    "  \"name\": \"Silicon Valley\",\n",
    "  \"type\": \"Scripted\",\n",
    "  \"language\": \"English\",\n",
    "  \"genres\": [\n",
    "    \"Comedy\"\n",
    "  ],\n",
    "  \"network\": {\n",
    "    \"id\": 8,\n",
    "    \"name\": \"HBO\",\n",
    "    \"country\": {\n",
    "      \"name\": \"United States\",\n",
    "      \"code\": \"US\",\n",
    "      \"timezone\": \"America/New_York\"\n",
    "    }\n",
    "  }\n",
    "}\"\"\"\n",
    "\n",
    "document=json.loads(sample_json)\n",
    "print(document)\n",
    "\n",
    "print(type(document))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8dd734c3-a347-4e18-9906-67255b1c93d8",
   "metadata": {},
   "source": [
    "## Reading JSON data in PySpark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae3e238c-1326-4b30-80a3-d391ceffc3d5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "shows=spark.read.json(data_path+'shows/shows-silicon-valley.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a203b283-6d95-4df1-b28b-5e2423ab631b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "shows.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33895527-0265-464f-a9d9-0a087c7b5bfc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "shows.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e88c40da-02f8-4278-a483-3d21c4584309",
   "metadata": {},
   "outputs": [],
   "source": [
    "# read multiple json files\n",
    "\n",
    "three_shows=spark.read.json(data_path+'shows/shows-*.json', multiLine=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0832077-83c3-46d7-b440-30db0b1c4fe0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "three_shows.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e9a7f3e-d7bd-41bc-9624-da713adbe2d0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "assert three_shows.count()==3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cb9dc3f-4c39-41a5-b05c-6c6744cc8639",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# look at the top columns of a json file\n",
    "print(shows.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf97c926-cbcd-4d6d-ad34-b8ee2679df72",
   "metadata": {},
   "source": [
    "### Work with array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2b079cd-e2b6-45d6-adc7-7656d4b2ceac",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Genres is stored as an array\n",
    "\n",
    "three_shows.select(F.col('name'), F.col('genres')).show(5, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "360cd15d-f7c6-4f97-8ec4-6b75d6cae0e5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# extract element of an array\n",
    "\n",
    "three_shows.select(F.col('genres')[0], F.col('genres').getItem(0)).show(5, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "735db154-39a4-4f3e-b6bb-64fd23869f33",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# extract element of an array and store it at a new column\n",
    "\n",
    "three_shows1=(three_shows.withColumn('genre1', F.col('genres')[0]).withColumn('genre2', F.col('genres')[1]).\n",
    "              withColumn('genre3', F.col('genres')[2]))\n",
    "\n",
    "three_shows1.select('genre1', 'genre2', 'genre3').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bf015d7-981b-41a6-976b-283d82afbe73",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# array function: size(), array(), array_distinct(), array_intersect(), array_repeat(), array_position()\n",
    "\n",
    "three_shows2=three_shows1.select('genre1', 'genre2', 'genre3')\n",
    "\n",
    "(three_shows2.select(F.array('genre1', 'genre2', 'genre3').alias('combined_genres'),\n",
    "                     F.array_repeat('combined_genres', 3).alias('repeated_genres'),\n",
    "                     F.array_distinct('repeated_genres').alias('genres_norepeat'),\n",
    "                     F.size(F.col('genres_norepeat')[0]).alias('array_size'),\n",
    "                     F.array_position('combined_genres','Comedy').alias('comedy_position')\n",
    "                    ).show(5, False))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "297159d3-9650-466a-9e87-a72db7a8614d",
   "metadata": {},
   "source": [
    "#### In class: display number of episodes for each show"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e7e8724-44ce-4321-a7af-0e3e2816a683",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "three_shows.select('name', '_embedded.episodes').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48c54b10-f3d5-4653-b9e6-04856620f0a3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "4d23d172-fb62-4067-99cc-d557eea36533",
   "metadata": {},
   "source": [
    "### The Map Type: Keys and Values within a column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4f02b46-789a-43bc-a3f7-5a39e4c58137",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "three_shows.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90fd8de9-8f93-4dbe-a62f-72de708f5681",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "three_shows.select('type').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c6ea012-4711-4975-9d64-03d6d13de484",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "columns=['name', 'language', 'type']\n",
    "\n",
    "shows_map1=three_shows.select(*[F.lit(column) for column in columns], F.array(*columns).alias('values'))\n",
    "\n",
    "shows_map1.show(3, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "777956ef-953d-404d-9be4-79a50e15e3b5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "shows_map2=shows_map1.select(F.array(*columns).alias('keys'), 'values')\n",
    "\n",
    "shows_map2.show(3, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "411ef164-91d9-44f0-8aa2-e2ec6f25a7a0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# create a map based on two arrays\n",
    "\n",
    "shows_map3=shows_map2.select(F.map_from_arrays(\"keys\", \"values\").alias(\"mapped\"))\n",
    "\n",
    "shows_map3.show(3, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a691306-15fa-42cd-841c-00f4cf068ea9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "shows_map3.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "625e0360-ddeb-40e6-babb-c48b5e2c7f84",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Three ways to access map value. Functions associated with map include map_value(), create_map()\n",
    "\n",
    "shows_map3.select(F.col('mapped.name'), F.col('mapped')[\"name\"], shows_map3.mapped['name']).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dab7f1d8-88ee-4e76-a94a-53da25990a5a",
   "metadata": {},
   "source": [
    "### the Struct: Nesting columns within columns\n",
    "\n",
    "The struct is very different from the array and the map in that the number of fields and their names are known ahead of time. In our case, the schedule struct column is fixed: we know that each record of our data frame will contain that schedule struct (or a null value, if we want to be pedantic), and within that struct there will be an array of strings, days, and a string, time. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e32069a-2f28-411c-94fd-6f1c4db1d17b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# The schedule column is a struct. It includes two columns: days and time\n",
    "\n",
    "three_shows.select(\"schedule\").printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8ef6e10-8f39-4a81-939f-a074165f5a47",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "three_shows.select(\"schedule\").show(5, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "769ba096-fdb9-4517-920e-3e5af6d43527",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# look at three _embedded column\n",
    "# major content is under episode\n",
    "\n",
    "three_shows.select(F.col(\"_embedded\")).printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "120e8b34-8647-4a24-a216-f45aeb59954b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# extract episodes\n",
    "\n",
    "shows_clean=three_shows.withColumn(\"episodes\", F.col('_embedded.episodes')).drop('_embedded')\n",
    "\n",
    "shows_clean.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a073b39-dca2-46ad-8cae-6d40259f863d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# extract a field from a stuct\n",
    "\n",
    "shows_clean.select(F.col('episodes.name')).show(3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "227a623e-ad16-49a3-8ffc-569114b6c4a3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# explode an array\n",
    "\n",
    "shows_clean.select(F.explode(F.col('episodes.name'))).show(10, False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84cc4b09-43ef-4380-98e8-f4230182dea8",
   "metadata": {},
   "source": [
    "### Building and Using the data frame schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef9326a0-adb0-4e81-b3fe-2edfe4259ebb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pyspark.sql.types as T\n",
    " \n",
    "episode_links_schema = T.StructType(\n",
    "    [\n",
    "        T.StructField(\n",
    "            \"self\", T.StructType([T.StructField(\"href\", T.StringType())]) \n",
    "        )\n",
    "    ]\n",
    ")  \n",
    "  \n",
    "episode_image_schema = T.StructType(\n",
    "    [\n",
    "        T.StructField(\"medium\", T.StringType()),                        \n",
    "        T.StructField(\"original\", T.StringType()),                       \n",
    "    ]\n",
    ")  \n",
    "  \n",
    "episode_schema = T.StructType(\n",
    "    [\n",
    "        T.StructField(\"_links\", episode_links_schema),                    \n",
    "        T.StructField(\"airdate\", T.DateType()),\n",
    "        T.StructField(\"airstamp\", T.TimestampType()),\n",
    "        T.StructField(\"airtime\", T.StringType()),\n",
    "        T.StructField(\"id\", T.StringType()),\n",
    "        T.StructField(\"image\", episode_image_schema),                    \n",
    "        T.StructField(\"name\", T.StringType()),\n",
    "        T.StructField(\"number\", T.LongType()),\n",
    "        T.StructField(\"runtime\", T.LongType()),\n",
    "        T.StructField(\"season\", T.LongType()),\n",
    "        T.StructField(\"summary\", T.StringType()),\n",
    "        T.StructField(\"url\", T.StringType()),\n",
    "    ]\n",
    ")\n",
    " \n",
    "embedded_schema = T.StructType(\n",
    "    [\n",
    "        T.StructField(\n",
    "            \"_embedded\",\n",
    "            T.StructType(\n",
    "                [\n",
    "                    T.StructField(\n",
    "                        \"episodes\", T.ArrayType(episode_schema)          \n",
    "                    )\n",
    "                ]\n",
    "            ),\n",
    "        )\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3f0f58f-c39c-477d-9922-efce0d31c4c6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# read the show data with defined schema\n",
    "\n",
    "shows_with_schema=spark.read.json(data_path+'shows/shows-*.json', multiLine=True,\n",
    "                  schema=embedded_schema,\n",
    "                  mode=\"FAILFAST\")\n",
    "\n",
    "shows_with_schema.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "501b4b1a-681d-4af5-8a39-b1c7c19efb99",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# verify the date type for the airdate and airstamp\n",
    "\n",
    "for column in ['airdate', 'airstamp']:\n",
    "    shows_with_schema.select(f\"_embedded.episodes.{column}\").select(F.explode(column)).show(5, False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04cd45ac-a2f1-46f1-8997-f822e0ccb6ff",
   "metadata": {},
   "source": [
    "### Getting to the \"just right\" data frame: Explode and collect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "483b2310-9afd-494c-baef-b8d365c54cba",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "## Explode\n",
    "episodes = shows.select(\n",
    "    \"id\", F.explode(\"_embedded.episodes\").alias(\"episodes\")\n",
    ")                                                              \n",
    "episodes.show(5, truncate=70)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56272edf-89b8-40f0-b5c8-018bb8e92afa",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "episodes.select('episodes').printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22814af9-7075-4389-9a5c-e757383dd41c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# extract the name from the above episodes dataframe\n",
    "\n",
    "e2=episodes.select('episodes')\n",
    "e2.select('episodes.name').show(5, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44929cc3-670f-4fa4-8bb7-ac053af07b86",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#posexplode: used to explode an array or a map column in a DataFrame into multiple rows, \n",
    "#while also preserving the position (index) of each element in the array or key in the map\n",
    "\n",
    "episode_name_id = shows.select(\n",
    "    F.map_from_arrays(                                         \n",
    "        F.col(\"_embedded.episodes.id\"), F.col(\"_embedded.episodes.name\")\n",
    "    ).alias(\"name_id\")\n",
    ")\n",
    " \n",
    "episode_name_id = episode_name_id.select(\n",
    "    F.posexplode(\"name_id\").alias(\"position\", \"id\", \"name\") \n",
    ")\n",
    " \n",
    "episode_name_id.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d91cd455-5d89-4ddf-8fc1-63e12eb29892",
   "metadata": {},
   "source": [
    "#### Note:\n",
    "Both explode() and posexplode() will skip any null values in the array or the map. If you want to have null as records, you can use explode_outer() or posexplode_outer() the same way."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acc9b14c-8b5a-4fd5-9d18-a5b50dd67938",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### In Calss 2  Display name of episode for each show\n",
    "collect_list(), collect_set()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53ba4a29-f68c-4e78-94e7-0a9876bc978b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "three_shows.select('name', '_embedded.episodes').show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7653e565-7880-4812-92ab-0dbb5db9c022",
   "metadata": {},
   "source": [
    "### In class exercise"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28bc4ce5-5fcb-4164-8591-e800fd1da1bc",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### Exercise 6.6\n",
    "Using three_shows, compute the time between the first and last episodes for each show (identifed by name). Which show had the longest tenure?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e3663c2-0e77-46a0-a719-8a97c69214ba",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "three_shows=spark.read.json(data_path+'shows/shows-*.json', multiLine=True)\n",
    "three_shows.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7f9ad25-7330-46a6-a299-4ac5253c5ed5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "three_shows.select('_embedded.episodes.airdate').show(5, truncate=500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4689120f-19a3-4e6d-a047-b01f472e77c3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df9ef764-44ea-4163-9633-2d4ccd67de2f",
   "metadata": {},
   "source": [
    "### exercise 6.7\n",
    "Take the shows data frame and extract the air date and name of each episode in two array columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b65e5300-17d6-42a3-9b16-f1ab77bca5b8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "three_shows=spark.read.json(data_path+'shows/shows-*.json', multiLine=True)\n",
    "#three_shows.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9808bddb-dfb5-4779-854f-fa5b5dd97164",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "1fd31f7b-3a28-408c-91f9-4b2d0907c252",
   "metadata": {},
   "source": [
    "#### Exercise 6.8\n",
    "\n",
    "Given the following data frame, create a new data frame that contains a single map from one to square:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c390b06f-1e4b-41b4-9ee7-d682e20300a4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "exo6_8 = spark.createDataFrame([[1, 2], [2, 4], [3, 9], [4, 16]], [\"one\", \"square\"])\n",
    "\n",
    "exo6_8.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33edfaeb-5e2b-414d-9ee9-519ceb7287ea",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "858a9e05-1cb7-42dc-8a56-5c0b2754ee24",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "BigDataEnv",
   "language": "python",
   "name": "bigdataenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
