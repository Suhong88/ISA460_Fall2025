{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "79b13537-88ff-433c-89f7-ce03bbf2458b",
   "metadata": {},
   "source": [
    "# Chapter 7 Bilingual PySpark: Blending Python and SQL code\n",
    "\n",
    "This chapter covers\n",
    "\n",
    "- Drawing a parallel between PySparkâ€™s instruction set and the SQL vocabulary\n",
    "- Registering data frames as temporary views or tables to query them using Spark SQL\n",
    "- Using the catalog to create, reference, and delete registered tables for SQL querying\n",
    "- Translating common data manipulations instructions from Python to SQL, and vice versa\n",
    "- Using SQL-style clauses inside certain PySpark methods"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c09a8f6-24c9-4a9a-af83-ae75b0c54ad3",
   "metadata": {},
   "source": [
    "# Start a pyspark session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c07b2616-6954-47b0-a518-7a5e4c3f6a93",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "25/10/19 16:47:07 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "25/10/19 16:47:07 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.\n",
      "25/10/19 16:47:07 WARN Utils: Service 'SparkUI' could not bind on port 4041. Attempting port 4042.\n",
      "25/10/19 16:47:07 WARN Utils: Service 'SparkUI' could not bind on port 4042. Attempting port 4043.\n",
      "25/10/19 16:47:07 WARN Utils: Service 'SparkUI' could not bind on port 4043. Attempting port 4044.\n",
      "25/10/19 16:47:07 WARN Utils: Service 'SparkUI' could not bind on port 4044. Attempting port 4045.\n",
      "25/10/19 16:47:07 WARN Utils: Service 'SparkUI' could not bind on port 4045. Attempting port 4046.\n",
      "25/10/19 16:47:07 WARN Utils: Service 'SparkUI' could not bind on port 4046. Attempting port 4047.\n",
      "25/10/19 16:47:07 WARN Utils: Service 'SparkUI' could not bind on port 4047. Attempting port 4048.\n",
      "25/10/19 16:47:07 WARN Utils: Service 'SparkUI' could not bind on port 4048. Attempting port 4049.\n",
      "25/10/19 16:47:07 WARN Utils: Service 'SparkUI' could not bind on port 4049. Attempting port 4050.\n",
      "25/10/19 16:47:07 WARN Utils: Service 'SparkUI' could not bind on port 4050. Attempting port 4051.\n",
      "25/10/19 16:47:07 WARN Utils: Service 'SparkUI' could not bind on port 4051. Attempting port 4052.\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.utils import AnalysisException\n",
    "import pyspark.sql.functions as F\n",
    "import pyspark.sql.types as T\n",
    "import helper_functions\n",
    "import os\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "import numpy as np\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# change the account name to your email account\n",
    "account='sli'\n",
    "\n",
    "# define a root path to access the data in the DataAnalysisWithPythonAndPySpark\n",
    "root_path='/net/clusterhn/home/'+account+'/isa460/data/'\n",
    "\n",
    "# check if the Spark session is active. If it is activate, close it\n",
    "\n",
    "try:\n",
    "    if spark:\n",
    "        spark.stop()\n",
    "except:\n",
    "    pass    \n",
    "\n",
    "spark = (SparkSession.builder.appName(\"Bilingual PySpark: Blending Python and SQL code\")\n",
    "        .config(\"spark.port.maxRetries\", \"100\")\n",
    "        .getOrCreate())\n",
    "\n",
    "# confiture the log level (defaulty is WARN)\n",
    "spark.sparkContext.setLogLevel('ERROR')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "16b3184c-00af-48ff-ae7f-abb8f0a19787",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+---------+------+----------+----------------+---------------+\n",
      "|AtomicNumber|Element  |Symbol|AtomicMass|NumberofNeutrons|NumberofProtons|\n",
      "+------------+---------+------+----------+----------------+---------------+\n",
      "|1           |Hydrogen |H     |1.007     |0               |1              |\n",
      "|2           |Helium   |He    |4.002     |2               |2              |\n",
      "|3           |Lithium  |Li    |6.941     |4               |3              |\n",
      "|4           |Beryllium|Be    |9.012     |5               |4              |\n",
      "|5           |Boron    |B     |10.811    |6               |5              |\n",
      "+------------+---------+------+----------+----------------+---------------+\n",
      "only showing top 5 rows\n",
      "\n",
      "+-----------------+------+-----+-----+-----------+-------+\n",
      "|NumberofElectrons|Period|Group|Phase|Radioactive|Natural|\n",
      "+-----------------+------+-----+-----+-----------+-------+\n",
      "|1                |1     |1    |gas  |NULL       |yes    |\n",
      "|2                |1     |18   |gas  |NULL       |yes    |\n",
      "|3                |2     |1    |solid|NULL       |yes    |\n",
      "|4                |2     |2    |solid|NULL       |yes    |\n",
      "|5                |2     |13   |solid|NULL       |yes    |\n",
      "+-----------------+------+-----+-----+-----------+-------+\n",
      "only showing top 5 rows\n",
      "\n",
      "+-----+--------+---------+--------------------+------------+-----------------+\n",
      "|Metal|Nonmetal|Metalloid|Type                |AtomicRadius|Electronegativity|\n",
      "+-----+--------+---------+--------------------+------------+-----------------+\n",
      "|NULL |yes     |NULL     |Nonmetal            |0.79        |2.2              |\n",
      "|NULL |yes     |NULL     |Noble Gas           |0.49        |NULL             |\n",
      "|yes  |NULL    |NULL     |Alkali Metal        |2.1         |0.98             |\n",
      "|yes  |NULL    |NULL     |Alkaline Earth Metal|1.4         |1.57             |\n",
      "|NULL |NULL    |yes      |Metalloid           |1.2         |2.04             |\n",
      "+-----+--------+---------+--------------------+------------+-----------------+\n",
      "only showing top 5 rows\n",
      "\n",
      "+---------------+-------+------------+------------+----------------+\n",
      "|FirstIonization|Density|MeltingPoint|BoilingPoint|NumberOfIsotopes|\n",
      "+---------------+-------+------------+------------+----------------+\n",
      "|13.5984        |8.99E-5|14.175      |20.28       |3               |\n",
      "|24.5874        |1.79E-4|NULL        |4.22        |5               |\n",
      "|5.3917         |0.534  |453.85      |1615.0      |5               |\n",
      "|9.3227         |1.85   |1560.15     |2742.0      |6               |\n",
      "|8.298          |2.34   |2573.15     |4200.0      |6               |\n",
      "+---------------+-------+------------+------------+----------------+\n",
      "only showing top 5 rows\n",
      "\n",
      "+----------+----+------------+--------------+---------------+\n",
      "|Discoverer|Year|SpecificHeat|NumberofShells|NumberofValence|\n",
      "+----------+----+------------+--------------+---------------+\n",
      "|Cavendish |1766|14.304      |1             |1              |\n",
      "|Janssen   |1868|5.193       |1             |NULL           |\n",
      "|Arfvedson |1817|3.582       |2             |1              |\n",
      "|Vaulquelin|1798|1.825       |2             |2              |\n",
      "|Gay-Lussac|1808|1.026       |2             |3              |\n",
      "+----------+----+------------+--------------+---------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from helper_functions import displayByGroup\n",
    "\n",
    "elements = spark.read.csv(\n",
    "    root_path+\"elements/Periodic_Table_Of_Elements.csv\",\n",
    "    header=True,\n",
    "    inferSchema=True)\n",
    "\n",
    "displayByGroup(elements, 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31a6bc73-d199-4634-b322-76309246ff86",
   "metadata": {},
   "source": [
    "# Register a data frame as a SQL table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a6bdebbe-ccde-47d6-9116-7ae68c934e04",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "elements.createOrReplaceTempView(\"elements_t\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ee242f81-e8ef-4da6-b77c-9d029b3ea842",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+--------+\n",
      "|period|count(1)|\n",
      "+------+--------+\n",
      "|     6|       1|\n",
      "|     4|       1|\n",
      "+------+--------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "query=\"select period, count(*) from elements_t where phase='liq' group by period\"\n",
    "spark.sql(query).show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d214ffae-251b-4ea3-a8d6-85ae0dab70d9",
   "metadata": {},
   "source": [
    "## Using the Spark catalog to manage SQL table/view"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b81adb2d-a9bd-4953-9047-9099c40cf8c5",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<pyspark.sql.catalog.Catalog at 0x7f8d7ec24740>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark.catalog"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9b63446b-fad6-42aa-9742-fda0c27a1173",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Table(name='elements_t', catalog=None, namespace=[], description=None, tableType='TEMPORARY', isTemporary=True)]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# list all sql tables\n",
    "spark.catalog.listTables()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "db336755-9cde-4c8b-a256-089a86436858",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# drop sql table/view\n",
    "\n",
    "spark.catalog.dropTempView(\"elements_t\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aab763d4-9433-44e4-8f54-7922026595f5",
   "metadata": {},
   "source": [
    "# Using SQL-style expressions in PySpark\n",
    "\n",
    "we will use a public data set provided by Backblaze, which provided hard-drive data and statistics. Backblaze is a company that provides cloud storage and backup. Since 2013, they have provided data on the drives in their data center, and over time have moved to a focus on failures and diagnosis. To get the files, you can download them from the website (http://mng.bz/4jZa). We will use the latest data in June 2025."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "55b8098a-d008-4add-b1ec-bda3ec2ddc82",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "df=spark.read.csv('/opt/shared/backblaze/', header=True, inferSchema=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "28a4e1ac-a5ee-4ac9-8c36-535756da7e0e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9618781"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82658b6a-7265-47f3-b5f9-3e2091ca2c97",
   "metadata": {},
   "source": [
    "## Identify the model having the highest failure rate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "01e32c19-4c53-4d2d-b274-e7b7cc6d96e0",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+--------------+----------------------------------+--------------+-------+\n",
      "|date      |serial_number |model                             |capacity_bytes|failure|\n",
      "+----------+--------------+----------------------------------+--------------+-------+\n",
      "|2025-06-13|2207E60CC65A  |CT250MX500SSD1                    |250059350016  |0      |\n",
      "|2025-06-13|2340E87B92B5  |CT250MX500SSD1                    |250059350016  |0      |\n",
      "|2025-06-13|2340E87B97E8  |CT250MX500SSD1                    |250059350016  |0      |\n",
      "|2025-06-13|2EGK64VX      |HGST HUH728080ALE604              |8001563222016 |0      |\n",
      "|2025-06-13|2EHZAKAX      |HGST HUH728080ALE604              |8001563222016 |0      |\n",
      "|2025-06-13|2EJ02A1X      |HGST HUH728080ALE604              |8001563222016 |0      |\n",
      "|2025-06-13|7LZ021LA      |Seagate BarraCuda SSD ZA250CM10002|250059350016  |0      |\n",
      "|2025-06-13|S2ZYJ9CF511681|ST500LM012 HN                     |500107862016  |0      |\n",
      "|2025-06-13|S2ZYJ9GGB01000|ST500LM012 HN                     |500107862016  |0      |\n",
      "|2025-06-13|S2ZYJ9GGB01001|ST500LM012 HN                     |500107862016  |0      |\n",
      "+----------+--------------+----------------------------------+--------------+-------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# select only the useful columns for our query\n",
    "selected_columns=['date',\n",
    " 'serial_number',\n",
    " 'model',\n",
    " 'capacity_bytes',\n",
    " 'failure']\n",
    "\n",
    "\n",
    "df1=df.select(selected_columns)\n",
    "\n",
    "df1.show(10, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "62cc8340-ceba-4b23-957d-db66d96d362e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+------------------+----------+-------+\n",
      "|               model|       capacity_GB|      date|failure|\n",
      "+--------------------+------------------+----------+-------+\n",
      "|      CT250MX500SSD1|232.88591766357422|2025-06-13|      0|\n",
      "|      CT250MX500SSD1|232.88591766357422|2025-06-13|      0|\n",
      "|      CT250MX500SSD1|232.88591766357422|2025-06-13|      0|\n",
      "|HGST HUH728080ALE604| 7452.036460876465|2025-06-13|      0|\n",
      "|HGST HUH728080ALE604| 7452.036460876465|2025-06-13|      0|\n",
      "|HGST HUH728080ALE604| 7452.036460876465|2025-06-13|      0|\n",
      "|Seagate BarraCuda...|232.88591766357422|2025-06-13|      0|\n",
      "|       ST500LM012 HN| 465.7617416381836|2025-06-13|      0|\n",
      "|       ST500LM012 HN| 465.7617416381836|2025-06-13|      0|\n",
      "|       ST500LM012 HN| 465.7617416381836|2025-06-13|      0|\n",
      "|       ST500LM012 HN| 465.7617416381836|2025-06-13|      0|\n",
      "|       ST500LM012 HN| 465.7617416381836|2025-06-13|      0|\n",
      "|       ST500LM012 HN| 465.7617416381836|2025-06-13|      0|\n",
      "|       ST500LM012 HN| 465.7617416381836|2025-06-13|      0|\n",
      "|       ST500LM012 HN| 465.7617416381836|2025-06-13|      0|\n",
      "|       ST500LM012 HN| 465.7617416381836|2025-06-13|      0|\n",
      "|       ST500LM012 HN| 465.7617416381836|2025-06-13|      0|\n",
      "|       ST500LM012 HN| 465.7617416381836|2025-06-13|      0|\n",
      "|       ST500LM012 HN| 465.7617416381836|2025-06-13|      0|\n",
      "|       ST500LM012 HN| 465.7617416381836|2025-06-13|      0|\n",
      "+--------------------+------------------+----------+-------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# get driver capacity in gigabytes\n",
    "\n",
    "df2=df1.selectExpr(\"model\", \"capacity_bytes/power(1024,3) capacity_GB\", \"date\", \"failure\")\n",
    "\n",
    "df2.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "721a2c55-b738-4dd2-8077-b11296ec6eee",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+------------------+-------+------+\n",
      "|               model|       capacity_GB|failure| count|\n",
      "+--------------------+------------------+-------+------+\n",
      "|      CT250MX500SSD1|232.88591766357422|      0| 21117|\n",
      "|         DELLBOSS VD|447.06915283203125|      0| 12929|\n",
      "|HGST HMS5C4040ALE640| 3726.023277282715|      0|   330|\n",
      "|HGST HMS5C4040BLE640| 3726.023277282715|      0|  5612|\n",
      "|HGST HMS5C4040BLE640| 3726.023277282715|      1|     1|\n",
      "|HGST HUH721010ALE600|            9314.0|      0|   598|\n",
      "|HGST HUH721212ALE600|           11176.0|      0| 78180|\n",
      "|HGST HUH721212ALE604|           11176.0|      1|    31|\n",
      "|HGST HUH721212ALE604|           11176.0|      0|400039|\n",
      "|HGST HUH721212ALN604|           11176.0|      0|299258|\n",
      "|HGST HUH721212ALN604|           11176.0|      1|    30|\n",
      "|HGST HUH728080ALE600| 7452.036460876465|      0| 32316|\n",
      "|HGST HUH728080ALE604| 7452.036460876465|      0|  2370|\n",
      "|HGST HUS728T8TALE6L4| 7452.036460876465|      0|   570|\n",
      "|       MTFDDAV240TCB|223.57088470458984|      0|  2580|\n",
      "|       MTFDDAV480TCB|447.13167572021484|      0|    60|\n",
      "|Micron 5300 MTFDD...|447.13167572021484|      0|    90|\n",
      "|      SSDSCKKB240GZR|223.57088470458984|      0|    30|\n",
      "|      SSDSCKKB480G8R|447.13167572021484|      0|    30|\n",
      "|       ST10000NM001G|            9314.0|      0|   837|\n",
      "+--------------------+------------------+-------+------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 90:====================================================>   (60 + 4) / 64]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+------------------+-------+----+\n",
      "|               model|       capacity_GB|      0|   1|\n",
      "+--------------------+------------------+-------+----+\n",
      "|       ST12000NM0117|           11176.0|    210|NULL|\n",
      "|      WDC WD5000LPCX| 465.7617416381836|   1440|NULL|\n",
      "|       MTFDDAV240TCB|223.57088470458984|   2580|NULL|\n",
      "|       MTFDDAV480TCB|447.13167572021484|     60|NULL|\n",
      "|       ST500LM012 HN| 465.7617416381836|   2165|NULL|\n",
      "|       ST12000NM0008|           11176.0| 566560|  46|\n",
      "|Seagate FireCuda ...| 465.7617416381836|    180|NULL|\n",
      "|     WUH721816ALE6L4|           14902.0|   3818|NULL|\n",
      "|       ST24000NM002H|           22352.0| 165035|  12|\n",
      "|Samsung SSD 850 E...| 931.5133895874023|     60|NULL|\n",
      "|       ST16000NM005G|           14902.0|    750|NULL|\n",
      "|     WDC WDS250G2B0A|232.88591766357422|   5004|NULL|\n",
      "| TOSHIBA MG10ACA20TE|           18627.0| 431902|   8|\n",
      "|       ST14000NM000J|           13039.0|   8983|   1|\n",
      "| TOSHIBA MG08ACA16TA|           14902.0|1203454|  43|\n",
      "|       ST16000NM002J|           14902.0|  13800|NULL|\n",
      "|      WDC WD5000BPKT| 465.7617416381836|    210|NULL|\n",
      "|       ST14000NM0138|           13039.0|  38690|   6|\n",
      "|       ST14000NM001G|           13039.0| 317016|   9|\n",
      "|Seagate BarraCuda...| 465.7617416381836|    330|NULL|\n",
      "+--------------------+------------------+-------+----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# calcualte failure rate by model\n",
    "\n",
    "df3=df2.filter(F.col('failure').isNotNull()).groupBy('model', 'capacity_GB', 'failure').count().orderBy('model', 'capacity_GB')\n",
    "\n",
    "df4=df3.groupBy('model', 'capacity_GB').pivot('failure').sum('count')\n",
    "\n",
    "df3.show()\n",
    "\n",
    "df4.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "4b858752-5c0a-4bea-b965-067a7246909e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 96:===================>                                   (23 + 41) / 64]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-----------------+-------+---+--------------------+\n",
      "|               model|      capacity_GB|      0|  1|        failure_rate|\n",
      "+--------------------+-----------------+-------+---+--------------------+\n",
      "| TOSHIBA MG09ACA16TE|          14902.0|   4705|  1|2.124946876328091...|\n",
      "|HGST HMS5C4040BLE640|3726.023277282715|   5612|  1|1.781578478531979...|\n",
      "|       ST14000NM0138|          13039.0|  38690|  6|1.550547860243953E-4|\n",
      "|       ST12000NM0007|          11176.0|  30217|  4|1.323582939015916E-4|\n",
      "|       ST14000NM000J|          13039.0|   8983|  1|1.113089937666963...|\n",
      "|HGST HUH721212ALN604|          11176.0| 299258| 30|1.002378979444548...|\n",
      "|       ST10000NM0086|           9314.0|  30301|  3|9.899683210137276E-5|\n",
      "|TOSHIBA MG08ACA16TEY|          14902.0| 153743| 14|9.105276507736233E-5|\n",
      "|       ST12000NM0008|          11176.0| 566560| 46|8.118516217618592E-5|\n",
      "|HGST HUH721212ALE604|          11176.0| 400039| 31|7.748643987302223E-5|\n",
      "|TOSHIBA MG07ACA14TEY|          13039.0|  26819|  2|7.456843518138772E-5|\n",
      "|       ST24000NM002H|          22352.0| 165035| 12| 7.27065623731422E-5|\n",
      "|        ST8000NM0055|7452.036460876465| 399791| 22|  5.5025724526216E-5|\n",
      "|         ST8000DM002|7452.036460876465| 269794| 13|4.818258977713699E-5|\n",
      "| WDC WUH721816ALE6L0|          14902.0|  89724|  4|4.457917261055635E-5|\n",
      "| TOSHIBA MG08ACA16TA|          14902.0|1203454| 43|3.572921245337545E-5|\n",
      "|       ST12000NM000J|          11176.0|  28794|  1|3.472825143254037E-5|\n",
      "|       ST12000NM001G|          11176.0| 397169| 12|3.021292559311749...|\n",
      "| TOSHIBA MG07ACA14TA|          13039.0|1124246| 32|2.846271117997505...|\n",
      "|       ST14000NM001G|          13039.0| 317016|  9|2.838892831795599...|\n",
      "+--------------------+-----------------+-------+---+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "df5=df4.fillna(0).withColumn('failure_rate', F.col('1')/(F.col('0')+F.col('1'))).orderBy(F.desc('failure_rate'))\n",
    "\n",
    "df5.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "6bb3eae2-7ce1-4d36-8c40-7f6ca86a1791",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 102:==================================================>    (59 + 5) / 64]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------------------+\n",
      "|corr(capacity_GB, failure_rate)|\n",
      "+-------------------------------+\n",
      "|             0.3752010764071598|\n",
      "+-------------------------------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# is there a correlation between capacity and failure_rate\n",
    "\n",
    "df5.select(F.corr('capacity_GB', 'failure_rate')).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fec07a0b-ed0c-468a-b7a4-e9e07d901ba8",
   "metadata": {},
   "source": [
    "## SQL and Pyspark code comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "bde8f1c0-9d90-496d-bae7-4ca2e62654e6",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "df=spark.read.csv('/opt/shared/backblaze/', header=True, inferSchema=True)\n",
    "\n",
    "selected_columns=['date',\n",
    " 'serial_number',\n",
    " 'model',\n",
    " 'capacity_bytes',\n",
    " 'failure']\n",
    "\n",
    "\n",
    "backblaze=df.select(selected_columns)\n",
    "\n",
    "backblaze.createOrReplaceTempView(\"backblaze_t\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "212178b9-4e4f-4c54-9408-7f0ce2f47fd4",
   "metadata": {
    "tags": []
   },
   "source": [
    "### display the top 3 models that have the highest max capacity\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "529b7d25-f0c6-4041-aade-a78cb96d4fc9",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 131:=============>                                        (16 + 48) / 64]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-------+-------+\n",
      "|               model| min_GB| max_GB|\n",
      "+--------------------+-------+-------+\n",
      "|       ST24000NM002H|22352.0|22352.0|\n",
      "| WDC WUH722222ALE6L4|20490.0|20490.0|\n",
      "| TOSHIBA MG10ACA20TE|18627.0|18627.0|\n",
      "|       ST18000NM000J|16764.0|16764.0|\n",
      "|TOSHIBA MG08ACA16TEY|14902.0|14902.0|\n",
      "+--------------------+-------+-------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# SQL way\n",
    "spark.sql(\n",
    "    \"\"\"SELECT\n",
    "           model,\n",
    "           min(capacity_bytes / pow(1024, 3)) min_GB,\n",
    "           max(capacity_bytes/ pow(1024, 3)) max_GB\n",
    "        FROM backblaze_t\n",
    "        GROUP BY 1\n",
    "        ORDER BY 3 DESC\"\"\"\n",
    ").show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "705813e9-38a0-4fd2-90fe-01863d142123",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 134:=======>                                               (9 + 55) / 64]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-------+-------+\n",
      "|               model| min_GB| max_GB|\n",
      "+--------------------+-------+-------+\n",
      "|       ST24000NM002H|22352.0|22352.0|\n",
      "| WDC WUH722222ALE6L4|20490.0|20490.0|\n",
      "| TOSHIBA MG10ACA20TE|18627.0|18627.0|\n",
      "|       ST18000NM000J|16764.0|16764.0|\n",
      "|TOSHIBA MG08ACA16TEY|14902.0|14902.0|\n",
      "+--------------------+-------+-------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "#Pyspark way\n",
    "\n",
    "backblaze.groupby(F.col(\"model\")).agg(\n",
    "    F.min(F.col(\"capacity_bytes\") / F.pow(F.lit(1024), 3)).alias(\"min_GB\"),\n",
    "    F.max(F.col(\"capacity_bytes\") / F.pow(F.lit(1024), 3)).alias(\"max_GB\"),\n",
    ").orderBy(F.col(\"max_GB\"), ascending=False).show(5) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65d39ee8-4db8-4687-8240-09c7927c963c",
   "metadata": {},
   "source": [
    "### display the top 3 models that have the highest max capacity, remove model that min capacity is equal to max capacity\n",
    "\n",
    "filtering after grouping using having"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "c42e489a-89ad-43de-b6a5-e58f53883f87",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 137:======================================================>(63 + 1) / 64]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+------+------+\n",
      "|model|min_GB|max_GB|\n",
      "+-----+------+------+\n",
      "+-----+------+------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# SQL way\n",
    "spark.sql(\n",
    "    \"\"\"SELECT\n",
    "           model,\n",
    "           min(capacity_bytes / pow(1024, 3)) min_GB,\n",
    "           max(capacity_bytes/ pow(1024, 3)) max_GB\n",
    "        FROM backblaze_t\n",
    "        GROUP BY 1\n",
    "        HAVING min_GB!=max_GB\n",
    "        ORDER BY 3 DESC\"\"\"\n",
    ").show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "27aff5b2-b5a2-4056-8fa7-575d588432d2",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 140:===============================================>       (55 + 9) / 64]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+------+------+\n",
      "|model|min_GB|max_GB|\n",
      "+-----+------+------+\n",
      "+-----+------+------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "#Pyspark way\n",
    "\n",
    "backblaze.groupby(F.col(\"model\")).agg(\n",
    "    F.min(F.col(\"capacity_bytes\") / F.pow(F.lit(1024), 3)).alias(\"min_GB\"),\n",
    "    F.max(F.col(\"capacity_bytes\") / F.pow(F.lit(1024), 3)).alias(\"max_GB\"),\n",
    ").where(F.col(\"min_GB\") != F.col(\"max_GB\")).orderBy(F.col(\"max_GB\"), ascending=False).show(5) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1ae4b6a-1e1d-4b31-ba13-f7d402f64401",
   "metadata": {},
   "source": [
    "## Creating new tables/views using the CREATE keyword"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "128310bf-5730-46ca-a20d-09bb5592b909",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark.sql(\n",
    "    \"\"\"\n",
    "    CREATE OR REPLACE TEMP VIEW drive_days AS\n",
    "        SELECT model, count(*) AS drive_days\n",
    "        FROM backblaze_t\n",
    "        GROUP BY model\"\"\"\n",
    ")\n",
    " \n",
    "spark.sql(\n",
    "    \"\"\"CREATE OR REPLACE TEMP VIEW failures AS\n",
    "           SELECT model, count(*) AS failures\n",
    "           FROM backblaze_t\n",
    "           WHERE failure = 1\n",
    "           GROUP BY model\"\"\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "bdccea13-be82-4d36-8e06-6cbc16b364d7",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Table(name='backblaze_t', catalog=None, namespace=[], description=None, tableType='TEMPORARY', isTemporary=True),\n",
       " Table(name='drive_days', catalog=None, namespace=[], description=None, tableType='TEMPORARY', isTemporary=True),\n",
       " Table(name='failures', catalog=None, namespace=[], description=None, tableType='TEMPORARY', isTemporary=True)]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark.catalog.listTables()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "914334c1-6ee8-4044-a4e9-7ac0211d9633",
   "metadata": {},
   "source": [
    "### Adding data to our table using UNION and JOIN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "db648050-c224-4f3c-a01c-81cc75ba585c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "backblaze_failure=backblaze.filter(F.col('failure')==1)\n",
    "backblaze_working=backblaze.filter(F.col('failure')==0)\n",
    "\n",
    "backblaze_failure.createOrReplaceTempView('backblaze_failure_t')\n",
    "backblaze_working.createOrReplaceTempView('backblaze_working_t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "afe6ff0e-ef75-4f79-a196-e03fef512ed7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# sql way\n",
    "spark.sql(\"\"\"\n",
    "        create or replace temp view backblaze_complete as\n",
    "        select * from backblaze_failure_t \n",
    "        union all\n",
    "        select * from backblaze_working_t\n",
    "\"\"\")\n",
    "\n",
    "#pyspark way\n",
    "\n",
    "backblaze_complet=backblaze_failure.union(backblaze_working)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "a154854a-87c1-402b-8a63-5b091829e7b6",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 148:==================================>                   (41 + 23) / 64]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+----------+--------+\n",
      "|               model|drive_days|failures|\n",
      "+--------------------+----------+--------+\n",
      "|      SSDSCKKB240GZR|        30|    NULL|\n",
      "|Seagate FireCuda ...|       180|    NULL|\n",
      "|         ST8000DM005|       720|    NULL|\n",
      "|       ST12000NM0007|     30221|       4|\n",
      "| TOSHIBA MQ01ABF050M|      3264|    NULL|\n",
      "+--------------------+----------+--------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# left join\n",
    "spark.sql(\n",
    "    \"\"\"select\n",
    "           drive_days.model,\n",
    "           drive_days,\n",
    "           failures\n",
    "    from drive_days\n",
    "    left join failures on drive_days.model = failures.model\"\"\"\n",
    ").show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70204ae7-2a68-4218-8d84-937c5d521438",
   "metadata": {},
   "source": [
    "### Organizing your SQL code better through subqueries and common table expressions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "394bbc15-6e0f-4aa7-96a0-d3e717dbb2e7",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+--------------+--------------------+--------------+-------+\n",
      "|      date| serial_number|               model|capacity_bytes|failure|\n",
      "+----------+--------------+--------------------+--------------+-------+\n",
      "|2025-06-13|  2207E60CC65A|      CT250MX500SSD1|  250059350016|      0|\n",
      "|2025-06-13|  2340E87B92B5|      CT250MX500SSD1|  250059350016|      0|\n",
      "|2025-06-13|  2340E87B97E8|      CT250MX500SSD1|  250059350016|      0|\n",
      "|2025-06-13|      2EGK64VX|HGST HUH728080ALE604| 8001563222016|      0|\n",
      "|2025-06-13|      2EHZAKAX|HGST HUH728080ALE604| 8001563222016|      0|\n",
      "|2025-06-13|      2EJ02A1X|HGST HUH728080ALE604| 8001563222016|      0|\n",
      "|2025-06-13|      7LZ021LA|Seagate BarraCuda...|  250059350016|      0|\n",
      "|2025-06-13|S2ZYJ9CF511681|       ST500LM012 HN|  500107862016|      0|\n",
      "|2025-06-13|S2ZYJ9GGB01000|       ST500LM012 HN|  500107862016|      0|\n",
      "|2025-06-13|S2ZYJ9GGB01001|       ST500LM012 HN|  500107862016|      0|\n",
      "|2025-06-13|S2ZYJ9GGB01021|       ST500LM012 HN|  500107862016|      0|\n",
      "|2025-06-13|S2ZYJ9GGB01024|       ST500LM012 HN|  500107862016|      0|\n",
      "|2025-06-13|S2ZYJ9GGB01033|       ST500LM012 HN|  500107862016|      0|\n",
      "|2025-06-13|S2ZYJ9GGB01039|       ST500LM012 HN|  500107862016|      0|\n",
      "|2025-06-13|S2ZYJ9GGB02709|       ST500LM012 HN|  500107862016|      0|\n",
      "|2025-06-13|S2ZYJ9GGB02828|       ST500LM012 HN|  500107862016|      0|\n",
      "|2025-06-13|S2ZYJ9KG926705|       ST500LM012 HN|  500107862016|      0|\n",
      "|2025-06-13|S2ZYJ9KG926707|       ST500LM012 HN|  500107862016|      0|\n",
      "|2025-06-13|S2ZYJ9KG926709|       ST500LM012 HN|  500107862016|      0|\n",
      "|2025-06-13|S2ZYJ9KG926711|       ST500LM012 HN|  500107862016|      0|\n",
      "+----------+--------------+--------------------+--------------+-------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"select * from backblaze_t\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "4edfb44c-a3a8-436c-83e3-e8cc7baee747",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 155:===============================================>       (55 + 9) / 64]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------------------+\n",
      "|               model|        failure_rate|\n",
      "+--------------------+--------------------+\n",
      "| TOSHIBA MG09ACA16TE|2.124946876328091...|\n",
      "|HGST HMS5C4040BLE640|1.781578478531979...|\n",
      "|       ST14000NM0138|1.550547860243953E-4|\n",
      "|       ST12000NM0007|1.323582939015916E-4|\n",
      "|       ST14000NM000J|1.113089937666963...|\n",
      "+--------------------+--------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# Finding drive models with highest failure rates using subqueries\n",
    "\n",
    "spark.sql(\n",
    "    \"\"\"\n",
    "    SELECT\n",
    "        failures.model,\n",
    "        failures / drive_days failure_rate\n",
    "    FROM (\n",
    "        SELECT\n",
    "            model,\n",
    "            count(*) AS drive_days\n",
    "        FROM backblaze_t\n",
    "        GROUP BY model) drive_days\n",
    "    INNER JOIN (\n",
    "        SELECT\n",
    "            model,\n",
    "            count(*) AS failures\n",
    "        FROM backblaze_t\n",
    "        WHERE failure = 1\n",
    "        GROUP BY model) failures\n",
    "    ON\n",
    "        drive_days.model = failures.model\n",
    "    ORDER BY 2 desc\n",
    "    \"\"\"\n",
    ").show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "215d62f5-42df-416f-8624-dd9f54b4f76a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 161:======================================================>(63 + 1) / 64]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------------------+\n",
      "|               model|        failure_rate|\n",
      "+--------------------+--------------------+\n",
      "| TOSHIBA MG09ACA16TE|2.124946876328091...|\n",
      "|HGST HMS5C4040BLE640|1.781578478531979...|\n",
      "|       ST14000NM0138|1.550547860243953E-4|\n",
      "|       ST12000NM0007|1.323582939015916E-4|\n",
      "|       ST14000NM000J|1.113089937666963...|\n",
      "+--------------------+--------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# Finding highest failure rates using common table expressions/CTE\n",
    "spark.sql(\n",
    "    \"\"\"\n",
    "    WITH drive_days as (            \n",
    "        SELECT                       \n",
    "            model,                   \n",
    "            count(*) AS drive_days   \n",
    "        FROM backblaze_t            \n",
    "        GROUP BY model),             \n",
    "    failures as (                    \n",
    "        SELECT                      \n",
    "            model,                   \n",
    "            count(*) AS failures    \n",
    "        FROM backblaze_t            \n",
    "        WHERE failure = 1           \n",
    "        GROUP BY model)              \n",
    "    SELECT\n",
    "        failures.model,\n",
    "        failures / drive_days failure_rate\n",
    "    FROM drive_days\n",
    "    INNER JOIN failures\n",
    "    ON\n",
    "        drive_days.model = failures.model\n",
    "    ORDER BY 2 desc\n",
    "    \"\"\"\n",
    ").show(5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "b2dc0540-856a-4eed-85be-9ba1171f7321",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Finding the highest failure rate using Python scope rules\n",
    "\n",
    "def failure_rate(df):\n",
    "    drive_days = df.groupby(F.col(\"model\")).agg(   \n",
    "        F.count(F.col(\"*\")).alias(\"drive_days\")\n",
    "    )\n",
    "    failures = (\n",
    "       df.where(F.col(\"failure\") == 1)\n",
    "        .groupby(F.col(\"model\"))\n",
    "        .agg(F.count(F.col(\"*\")).alias(\"failures\"))\n",
    "    )\n",
    "    answer = (                                               \n",
    "        drive_days.join(failures, on=\"model\", how=\"inner\")\n",
    "        .withColumn(\"failure_rate\", F.col(\"failures\") / F.col(\"drive_days\"))\n",
    "        .orderBy(F.col(\"failure_rate\").desc())\n",
    "    )\n",
    "    return answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "45df5c27-72e6-4927-a59a-8d51096cbe11",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 167:===================================================>   (60 + 4) / 64]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+----------+--------+--------------------+\n",
      "|               model|drive_days|failures|        failure_rate|\n",
      "+--------------------+----------+--------+--------------------+\n",
      "| TOSHIBA MG09ACA16TE|      4706|       1|2.124946876328091...|\n",
      "|HGST HMS5C4040BLE640|      5613|       1|1.781578478531979...|\n",
      "|       ST14000NM0138|     38696|       6|1.550547860243953E-4|\n",
      "|       ST12000NM0007|     30221|       4|1.323582939015916E-4|\n",
      "|       ST14000NM000J|      8984|       1|1.113089937666963...|\n",
      "|HGST HUH721212ALN604|    299288|      30|1.002378979444548...|\n",
      "|       ST10000NM0086|     30304|       3|9.899683210137276E-5|\n",
      "|TOSHIBA MG08ACA16TEY|    153757|      14|9.105276507736233E-5|\n",
      "|       ST12000NM0008|    566606|      46|8.118516217618592E-5|\n",
      "|HGST HUH721212ALE604|    400070|      31|7.748643987302223E-5|\n",
      "|TOSHIBA MG07ACA14TEY|     26821|       2|7.456843518138772E-5|\n",
      "|       ST24000NM002H|    165047|      12| 7.27065623731422E-5|\n",
      "|        ST8000NM0055|    399813|      22|  5.5025724526216E-5|\n",
      "|         ST8000DM002|    269807|      13|4.818258977713699E-5|\n",
      "| WDC WUH721816ALE6L0|     89728|       4|4.457917261055635E-5|\n",
      "| TOSHIBA MG08ACA16TA|   1203497|      43|3.572921245337545E-5|\n",
      "|       ST12000NM000J|     28795|       1|3.472825143254037E-5|\n",
      "|       ST12000NM001G|    397181|      12|3.021292559311749...|\n",
      "| TOSHIBA MG07ACA14TA|   1124278|      32|2.846271117997505...|\n",
      "|       ST14000NM001G|    317025|       9|2.838892831795599...|\n",
      "+--------------------+----------+--------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "failure_rate(backblaze).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "988802ff-f73b-48c5-9404-16e1a8b10fb4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def most_reliable_drive_for_capacity(data, capacity_GB=2048, precision=0.25, top_n=3):\n",
    "    \"\"\"Returns the top 3 drives for a given approximate capacity.\n",
    " \n",
    "    Given a capacity in GB and a precision as a decimal number, we keep the N\n",
    "    drives where:\n",
    " \n",
    "    - the capacity is between (capacity * 1/(1+precision)), capacity * (1+precision)\n",
    "    - the failure rate is the lowest\n",
    " \n",
    "    \"\"\"\n",
    "    capacity_min = capacity_GB / (1 + precision)\n",
    "    capacity_max = capacity_GB * (1 + precision)\n",
    " \n",
    "    answer = (\n",
    "        data.where(f\"capacity_GB between {capacity_min} and {capacity_max}\")\n",
    "        .orderBy(\"failure_rate\", \"capacity_GB\", ascending=[True, False])\n",
    "        .limit(top_n)                                                     \n",
    "     )\n",
    " \n",
    "    return answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "b6cdffe4-4af2-4eac-ab9d-5024f001b3cc",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 172:=============================================>        (54 + 10) / 64]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+-----------+----+---+------------+\n",
      "|        model|capacity_GB|   0|  1|failure_rate|\n",
      "+-------------+-----------+----+---+------------+\n",
      "|ST14000NM002J|    13039.0| 150|  0|         0.0|\n",
      "|ST14000NM0018|    13039.0|1920|  0|         0.0|\n",
      "|ST12000NM0117|    11176.0| 210|  0|         0.0|\n",
      "+-------------+-----------+----+---+------------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "backblaze1=backblaze.withColumn('capacity_GB', F.col(\"capacity_bytes\") / F.pow(F.lit(1024), 3))\n",
    "\n",
    "most_reliable_drive_for_capacity(df5, capacity_GB=11176.0).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45b87e86-1c5f-437e-ada2-41b9e3999986",
   "metadata": {},
   "source": [
    "#Summary\n",
    "\n",
    "- Spark provides a SQL API for data manipulation. This API supports ANSI SQL.\n",
    "- Spark (and PySpark, by extension) borrows a lot of vocabulary and expected functionality from the way SQL manipulates tables. This is especially evident since the data manipulation module is called pyspark.sql.\n",
    "- PySparkâ€™s data frames need to be registered as views or tables before they can be queried with Spark SQL. You can give them a different name than the data frame youâ€™re registering.\n",
    "- PySparkâ€™s own data frame manipulation methods and functions borrow SQL functionality, for the most part. Some exceptions, such as union(), are present and documented in the API.\n",
    "- Spark SQL queries can be inserted in a PySpark program through the spark.sql function, where spark is the running SparkSession.\n",
    "- Spark SQL table references are kept in a Catalog, which contains the metadata for all tables accessible to Spark SQL.\n",
    "- PySpark will accept SQL-style clauses in where(), expr(), and selectExpr(), which can simplify the syntax for complex filtering and selection.\n",
    "- When using Spark SQL queries with user-provided input, be careful with sanitizing the inputs to avoid potential SQL injection attacks."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c2ea7a1-9045-47cb-bdca-5c7c9dbcd9c3",
   "metadata": {},
   "source": [
    "## In class exercise\n",
    "\n",
    "display average failure rate of driver by day, order by day, and visualize the result.\n",
    "\n",
    "Use both SQL and pyspark to get the answer. Which one you prefer?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "6b9ddb4d-fe9c-4246-9b18-1ca4659abf87",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "df=spark.read.csv('/opt/shared/backblaze/', header=True, inferSchema=True)\n",
    "\n",
    "selected_columns=['date',\n",
    " 'serial_number',\n",
    " 'model',\n",
    " 'capacity_bytes',\n",
    " 'failure']\n",
    "\n",
    "\n",
    "backblaze=df.select(selected_columns)\n",
    "\n",
    "backblaze.createOrReplaceTempView(\"backblaze_t\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19e0ec48-8113-4103-ac71-7a3109708c24",
   "metadata": {},
   "source": [
    "## PySpark way"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "def454e5-cbb5-41d6-8e50-e53161375b8e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a841165-0cd8-480c-a77f-53233eb374b7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d16aae91-8e64-4f6a-a7e2-fdddd275d833",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "2127749c-4221-4018-a286-a1ad7f870d7f",
   "metadata": {},
   "source": [
    "## SQL way"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb1c30dc-fd5b-47ad-a641-8aa8e7956327",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e601734-6259-4cea-b7ff-6fc343b5f348",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b7dc12ff-1c10-4456-9f27-6b91d82b2b3b",
   "metadata": {},
   "source": [
    "## visualize the result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e39d762-ea5e-49f0-aa09-3b18243af97f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "127343b3-a11f-4668-aec5-50a22ba8c356",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1dbe2dce-0640-46c1-98a3-f6b3452c4c9c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "BigDataEnv",
   "language": "python",
   "name": "bigdataenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
