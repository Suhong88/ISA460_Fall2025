{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0e9954ae-938e-4ed4-bfb5-254897867c07",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Project three: heart disease classification\n",
    "\n",
    "## About Dataset\n",
    "Cardiovascular illnesses (CVDs) are the major cause of death worldwide. CVDs include coronary heart disease, cerebrovascular disease, rheumatic heart disease, and other heart and blood vessel problems. According to the World Health Organization, 17.9 million people die each year. Heart attacks and strokes account for more than four out of every five CVD deaths, with one-third of these deaths occurring before the age of 70. A comprehensive database for factors that contribute to a heart attack has been constructed.\n",
    "\n",
    "The main purpose here is to collect characteristics of Heart Attack or factors that contribute to it.\n",
    "The size of the dataset is 1319 samples, which have nine fields, where eight fields are for input fields and one field for an output field. Age, gender(0 for Female, 1 for Male) ,heart rate (impulse), systolic BP (pressurehight), diastolic BP (pressurelow), blood sugar(glucose), CK-MB (kcm), and Test-Troponin (troponin) are representing the input fields, while the output field pertains to the presence of heart attack (class), which is divided into two categories (negative and positive); negative refers to the absence of a heart attack, while positive refers to the presence of a heart attack.\n",
    "\n",
    "You will build a classification model to predict the presence of heart attack. As a starting point, I have built a logistics regression and a decision tree model for your reference. \n",
    "\n",
    "Please check the below site for possible classification models you can run in spark. \n",
    "[Spark MLLib for Classification](https://spark.apache.org/docs/latest/ml-classification-regression.html#decision-tree-classifier)\n",
    "\n",
    "Please run at least two other algorithms for classification based on this dataset and disucss the performance of each model (using f1 score). Which model generates the best result? what features are the most important in explaining the result? In addition, try some strategies to imporve the performance of the modes and discuss your experience/lessons learned. Were you be able to imporve the performance of the model and why? Please write your response at the end of this notebook as markdown cell.\n",
    "\n",
    "## Strategy to improve the model (some may be not applicable to this dataset):\n",
    "- remove/replace outliers\n",
    "- find better ways to deal with missing values\n",
    "- add/delete/modify features, create additional features based on existing features\n",
    "- conduct hyper-parameters tuning and cross-validation\n",
    "- try different models/algorithms\n",
    "- use more data or anything else you find helpful"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "646d1f62-9544-4477-9e06-6c04918cb5d7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "import pyspark.sql.functions as F\n",
    "#from helper_functions import displayByGroup\n",
    "import os\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# check if the Spark session is active. If it is activate, close it\n",
    "\n",
    "try:\n",
    "    if spark:\n",
    "        spark.stop()\n",
    "except:\n",
    "    pass    \n",
    "\n",
    "spark = (SparkSession.builder.appName(\"Heart Attack Prediction\")\n",
    "        .config(\"spark.port.maxRetries\", \"200\")\n",
    "        .config(\"spark.sql.mapKeyDedupPolicy\", \"LAST_WIN\")  # This configuration allow the duplicate keys in the map data type.\n",
    "        .config(\"spark.driver.memory\", \"16g\")\n",
    "        .getOrCreate())\n",
    "\n",
    "# confiture the log level (defaulty is WWARN)\n",
    "spark.sparkContext.setLogLevel('ERROR')\n",
    "\n",
    "# read the global warming tweets\n",
    "\n",
    "df=spark.read.csv('/opt/shared/Heart_Attack.csv', header=True, inferSchema=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "5da9113a-196f-47f9-9461-5f7adaa9dced",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+------+-------+-------------+-----------+-------+-----+--------+--------+\n",
      "|age|gender|impluse|pressurehight|pressurelow|glucose|  kcm|troponin|   class|\n",
      "+---+------+-------+-------------+-----------+-------+-----+--------+--------+\n",
      "| 64|     1|     66|          160|         83|  160.0|  1.8|   0.012|negative|\n",
      "| 21|     1|     94|           98|         46|  296.0| 6.75|    1.06|positive|\n",
      "| 55|     1|     64|          160|         77|  270.0| 1.99|   0.003|negative|\n",
      "| 64|     1|     70|          120|         55|  270.0|13.87|   0.122|positive|\n",
      "| 55|     1|     64|          112|         65|  300.0| 1.08|   0.003|negative|\n",
      "| 58|     0|     61|          112|         58|   87.0| 1.83|   0.004|negative|\n",
      "| 32|     0|     40|          179|         68|  102.0| 0.71|   0.003|negative|\n",
      "| 63|     1|     60|          214|         82|   87.0|300.0|    2.37|positive|\n",
      "| 44|     0|     60|          154|         81|  135.0| 2.35|   0.004|negative|\n",
      "| 67|     1|     61|          160|         95|  100.0| 2.84|   0.011|negative|\n",
      "| 44|     0|     60|          166|         90|  102.0| 2.39|   0.006|negative|\n",
      "| 63|     0|     60|          150|         83|  198.0| 2.39|   0.013|negative|\n",
      "| 64|     1|     60|          199|         99|   92.0| 3.43|    5.37|positive|\n",
      "| 54|     0|     94|          122|         67|   97.0| 1.42|   0.012|negative|\n",
      "| 47|     1|     76|          120|         70|  319.0| 2.57|   0.003|negative|\n",
      "| 61|     1|     81|          118|         66|  134.0| 1.49|   0.017|positive|\n",
      "| 86|     0|     73|          114|         68|   87.0| 1.11|   0.776|positive|\n",
      "| 45|     0|     70|          100|         68|   96.0|0.606|   0.004|negative|\n",
      "| 37|     0|     72|          107|         86|  274.0| 2.89|   0.003|negative|\n",
      "| 45|     1|     60|          109|         65|   89.0|  1.6|    0.02|positive|\n",
      "+---+------+-------+-------------+-----------+-------+-----+--------+--------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "0fdfbf95-2690-43d0-b106-9e7fb90df512",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- age: integer (nullable = true)\n",
      " |-- gender: integer (nullable = true)\n",
      " |-- impluse: integer (nullable = true)\n",
      " |-- pressurehight: integer (nullable = true)\n",
      " |-- pressurelow: integer (nullable = true)\n",
      " |-- glucose: double (nullable = true)\n",
      " |-- kcm: double (nullable = true)\n",
      " |-- troponin: double (nullable = true)\n",
      " |-- class: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "25f2b205-470b-4eb4-870c-32c04301efa6",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+------+-------+-------------+-----------+-------+-----+--------+--------+-----+\n",
      "|age|gender|impluse|pressurehight|pressurelow|glucose|  kcm|troponin|   class|label|\n",
      "+---+------+-------+-------------+-----------+-------+-----+--------+--------+-----+\n",
      "| 64|     1|     66|          160|         83|  160.0|  1.8|   0.012|negative|    0|\n",
      "| 21|     1|     94|           98|         46|  296.0| 6.75|    1.06|positive|    1|\n",
      "| 55|     1|     64|          160|         77|  270.0| 1.99|   0.003|negative|    0|\n",
      "| 64|     1|     70|          120|         55|  270.0|13.87|   0.122|positive|    1|\n",
      "| 55|     1|     64|          112|         65|  300.0| 1.08|   0.003|negative|    0|\n",
      "| 58|     0|     61|          112|         58|   87.0| 1.83|   0.004|negative|    0|\n",
      "| 32|     0|     40|          179|         68|  102.0| 0.71|   0.003|negative|    0|\n",
      "| 63|     1|     60|          214|         82|   87.0|300.0|    2.37|positive|    1|\n",
      "| 44|     0|     60|          154|         81|  135.0| 2.35|   0.004|negative|    0|\n",
      "| 67|     1|     61|          160|         95|  100.0| 2.84|   0.011|negative|    0|\n",
      "| 44|     0|     60|          166|         90|  102.0| 2.39|   0.006|negative|    0|\n",
      "| 63|     0|     60|          150|         83|  198.0| 2.39|   0.013|negative|    0|\n",
      "| 64|     1|     60|          199|         99|   92.0| 3.43|    5.37|positive|    1|\n",
      "| 54|     0|     94|          122|         67|   97.0| 1.42|   0.012|negative|    0|\n",
      "| 47|     1|     76|          120|         70|  319.0| 2.57|   0.003|negative|    0|\n",
      "| 61|     1|     81|          118|         66|  134.0| 1.49|   0.017|positive|    1|\n",
      "| 86|     0|     73|          114|         68|   87.0| 1.11|   0.776|positive|    1|\n",
      "| 45|     0|     70|          100|         68|   96.0|0.606|   0.004|negative|    0|\n",
      "| 37|     0|     72|          107|         86|  274.0| 2.89|   0.003|negative|    0|\n",
      "| 45|     1|     60|          109|         65|   89.0|  1.6|    0.02|positive|    1|\n",
      "+---+------+-------+-------------+-----------+-------+-----+--------+--------+-----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# create label (target variable)\n",
    "\n",
    "df1=df.withColumn('label', F.when(F.col('class')==\"positive\", 1).otherwise(0))\n",
    "\n",
    "df1.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "10dfb112-16be-48b5-90c0-c90eba8bc40c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+-----+\n",
      "|label|count|\n",
      "+-----+-----+\n",
      "|    1|  810|\n",
      "|    0|  509|\n",
      "+-----+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df1.groupBy('label').count().show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b5bae7a-9bfe-44e4-ac99-cec2a37421c2",
   "metadata": {},
   "source": [
    "## Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "04374d9b-a3d6-408e-b79d-24aa1cef4b76",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import StringIndexer, VectorAssembler\n",
    "\n",
    "#Split the model into train and test dataset\n",
    "\n",
    "(trainDF, testDF) = df1.randomSplit([.8, .2], seed=42)\n",
    "\n",
    "# we only have numerous features, and we can directly assemble all featuress into one vector\n",
    "# need to remove target varible\n",
    "\n",
    "numericCols = [field for (field, dataType) in df1.dtypes if (((dataType == \"double\")|(dataType == \"int\")) & (field != \"label\"))]\n",
    "\n",
    "vecAssembler = VectorAssembler(inputCols=numericCols, outputCol=\"features\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "59e78953-3d18-4eca-b116-4a7c7b878b26",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['age',\n",
       " 'gender',\n",
       " 'impluse',\n",
       " 'pressurehight',\n",
       " 'pressurelow',\n",
       " 'glucose',\n",
       " 'kcm',\n",
       " 'troponin']"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check numerical features and make sure it look correct\n",
    "\n",
    "numericCols"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51ad2cb4-e7c2-4e8c-8dd7-aa46383cb507",
   "metadata": {},
   "source": [
    "## Logistics Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "018305d9-43a3-4603-a6c5-d75a0b863fc0",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistics Regression areaUnderROC 0.9227418207681363\n",
      "Logistics Regression areaUnderPR  0.9375381601020925\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.classification import LogisticRegression\n",
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.evaluation import BinaryClassificationEvaluator\n",
    "\n",
    "# Create initial LogisticRegression model\n",
    "\n",
    "lr = LogisticRegression(maxIter=10)\n",
    "\n",
    "pipeline=Pipeline(stages=[vecAssembler, lr])\n",
    "\n",
    "#train the model\n",
    "\n",
    "pipelineModel_lr=pipeline.fit(trainDF)\n",
    "\n",
    "#evaluate the model\n",
    "\n",
    "lr_predDF = pipelineModel_lr.transform(testDF)\n",
    " \n",
    "# Using areaUnderROC and areadUnderPR to evaluate binary classification model. roc is default measurement\n",
    "\n",
    "evaluator_roc = BinaryClassificationEvaluator()\n",
    "\n",
    "evaluator_pr=BinaryClassificationEvaluator(metricName=\"areaUnderPR\")\n",
    "\n",
    "# Evaluate logistic regression model \n",
    "\n",
    "print(\"Logistics Regression areaUnderROC\", evaluator_roc.evaluate(lr_predDF))\n",
    "\n",
    "print(\"Logistics Regression areaUnderPR \", evaluator_pr.evaluate(lr_predDF))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "686cc17b-4d8a-47e0-93b5-73cd5b8e3141",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['age',\n",
       " 'gender',\n",
       " 'impluse',\n",
       " 'pressurehight',\n",
       " 'pressurelow',\n",
       " 'glucose',\n",
       " 'kcm',\n",
       " 'troponin',\n",
       " 'class',\n",
       " 'label',\n",
       " 'features',\n",
       " 'rawPrediction',\n",
       " 'probability',\n",
       " 'prediction']"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr_predDF.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "1f58061a-6a6d-46e5-9949-fa0617c965af",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------------------------------+-----+-----------------------------------------+----------+\n",
      "|features                                   |label|probability                              |prediction|\n",
      "+-------------------------------------------+-----+-----------------------------------------+----------+\n",
      "|[19.0,0.0,70.0,117.0,76.0,91.0,36.24,0.025]|1    |[4.448496480215476E-8,0.9999999555150352]|1.0       |\n",
      "|[21.0,0.0,62.0,76.0,55.0,111.0,3.11,0.003] |0    |[0.9378836037770448,0.06211639622295517] |0.0       |\n",
      "|[21.0,1.0,85.0,204.0,84.0,93.0,2.71,0.002] |0    |[0.9562668272098092,0.043733172790190844]|0.0       |\n",
      "|[22.0,1.0,84.0,160.0,79.0,102.0,2.25,0.006]|0    |[0.953170217306127,0.046829782693872946] |0.0       |\n",
      "|[25.0,1.0,64.0,153.0,93.0,110.0,3.09,0.097]|1    |[0.41696592150395756,0.5830340784960424] |1.0       |\n",
      "|[26.0,1.0,54.0,104.0,62.0,88.0,14.21,0.004]|1    |[0.015205955775295755,0.9847940442247043]|1.0       |\n",
      "|[27.0,1.0,94.0,157.0,79.0,141.0,6.25,0.003]|1    |[0.6223079733884556,0.37769202661154444] |0.0       |\n",
      "|[28.0,0.0,96.0,105.0,75.0,294.0,1.45,0.003]|0    |[0.961855406111251,0.03814459388874902]  |0.0       |\n",
      "|[29.0,1.0,76.0,157.0,93.0,242.0,4.79,0.004]|0    |[0.7407313130758261,0.25926868692417393] |0.0       |\n",
      "|[29.0,1.0,81.0,150.0,51.0,100.0,6.48,0.003]|1    |[0.6250197876971644,0.3749802123028356]  |0.0       |\n",
      "+-------------------------------------------+-----+-----------------------------------------+----------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "lr_predDF.select('features', 'label', 'probability', 'prediction').show(10, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "118b4db7-24ac-4f17-8645-17fc69f325ba",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "def classification_performance(predDF):\n",
    "  \n",
    "  pd_prediction=predDF.select('label', 'prediction').toPandas()\n",
    "  label=pd_prediction['label']\n",
    "  pred=pd_prediction['prediction']\n",
    " \n",
    "  confusion=confusion_matrix(label, pred)\n",
    "\n",
    "  print('Confusion Matrix\\n', confusion)\n",
    "\n",
    "  print('\\nClassification Report\\n')\n",
    "\n",
    "  print(classification_report(label, pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "6f3ed3f7-11e7-4541-a862-df0727ddebd6",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix\n",
      " [[ 60  14]\n",
      " [ 24 128]]\n",
      "\n",
      "Classification Report\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.71      0.81      0.76        74\n",
      "           1       0.90      0.84      0.87       152\n",
      "\n",
      "    accuracy                           0.83       226\n",
      "   macro avg       0.81      0.83      0.82       226\n",
      "weighted avg       0.84      0.83      0.83       226\n",
      "\n"
     ]
    }
   ],
   "source": [
    "classification_performance(lr_predDF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "88e5880b-043a-4e56-8870-c5dc4ebfe75b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# option 1: extract feature importance\n",
    "\n",
    "# define a function to return feature names for logisitcs regression\n",
    "def feature_names(df, features):\n",
    "  featureIndex=df.schema[features].metadata[\"ml_attr\"][\"attrs\"]\n",
    " \n",
    "  feature_names=[]\n",
    "  # print numeric feature\n",
    "  for x in range(len(df.schema[features].metadata[\"ml_attr\"][\"attrs\"]['numeric'])):\n",
    "    try:\n",
    "      feature_names.append(featureIndex[\"numeric\"][x]['name'])\n",
    "    except:\n",
    "      continue\n",
    " # print binary feature\n",
    "  try:\n",
    "      for x in range(len(df.schema[features].metadata[\"ml_attr\"][\"attrs\"]['binary'])):\n",
    "        try:\n",
    "           feature_names.append(featureIndex[\"binary\"][x]['name'])\n",
    "        except:\n",
    "          continue\n",
    "  except:\n",
    "     return feature_names\n",
    "\n",
    "# feature importance\n",
    "def lr_coefficients(df, model, features=\"features\"):\n",
    "  coefficients =model.coefficients\n",
    "  names=feature_names(df, features)\n",
    " \n",
    "  weightsDF = pd.DataFrame(zip(names, coefficients, list(map(abs, coefficients))), columns=['feature', 'weights', 'abs_weights'])\n",
    "  sorted_list=weightsDF.sort_values('abs_weights', ascending=False)[['feature', 'weights']]\n",
    "  return sorted_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "fe2eac01-6044-414c-bb05-02c596c8f009",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature</th>\n",
       "      <th>weights</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>troponin</td>\n",
       "      <td>27.671303</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>kcm</td>\n",
       "      <td>0.577681</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>gender</td>\n",
       "      <td>0.247278</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>age</td>\n",
       "      <td>0.053819</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>pressurelow</td>\n",
       "      <td>0.010215</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>pressurehight</td>\n",
       "      <td>-0.005063</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>impluse</td>\n",
       "      <td>-0.000221</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>glucose</td>\n",
       "      <td>0.000106</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         feature    weights\n",
       "7       troponin  27.671303\n",
       "6            kcm   0.577681\n",
       "1         gender   0.247278\n",
       "0            age   0.053819\n",
       "4    pressurelow   0.010215\n",
       "3  pressurehight  -0.005063\n",
       "2        impluse  -0.000221\n",
       "5        glucose   0.000106"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr_coefficients(lr_predDF, pipelineModel_lr.stages[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "a25df7d3-bea9-41c7-b21b-b029c7533935",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature</th>\n",
       "      <th>coefficient</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>troponin</td>\n",
       "      <td>27.671303</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>kcm</td>\n",
       "      <td>0.577681</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>gender</td>\n",
       "      <td>0.247278</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>age</td>\n",
       "      <td>0.053819</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>pressurelow</td>\n",
       "      <td>0.010215</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>pressurehight</td>\n",
       "      <td>-0.005063</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>impluse</td>\n",
       "      <td>-0.000221</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>glucose</td>\n",
       "      <td>0.000106</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         feature  coefficient\n",
       "7       troponin    27.671303\n",
       "6            kcm     0.577681\n",
       "1         gender     0.247278\n",
       "0            age     0.053819\n",
       "4    pressurelow     0.010215\n",
       "3  pressurehight    -0.005063\n",
       "2        impluse    -0.000221\n",
       "5        glucose     0.000106"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# option 2: extract feature importance\n",
    "\n",
    "feature_names=pipelineModel_lr.stages[0].getInputCols()\n",
    "coefficients=pipelineModel_lr.stages[1].coefficients\n",
    "\n",
    "weightsDF = pd.DataFrame(zip(feature_names, coefficients, list(map(abs, coefficients))), columns=['feature', 'coefficient', 'abs_coefficient'])\n",
    "sorted_list=weightsDF.sort_values('abs_coefficient', ascending=False)[['feature', 'coefficient']]\n",
    "\n",
    "sorted_list.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c7329d2-26b7-4065-8754-7fd1f276f963",
   "metadata": {},
   "source": [
    "## Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "5c1d05ca-ff3f-4475-a25c-b383c690447d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decision Tree areaUnderROC  0.9657272403982928\n",
      "Deccision Tree areaUnderPR  0.9832849007422954\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.classification import DecisionTreeClassifier\n",
    "from pyspark.ml.evaluation import BinaryClassificationEvaluator\n",
    "\n",
    "# Train a Decision Tree model.\n",
    "dt = DecisionTreeClassifier(seed=42)\n",
    "\n",
    "pipeline=Pipeline(stages=[vecAssembler, dt])\n",
    "\n",
    "#train the model\n",
    "\n",
    "pipelineModel_dt=pipeline.fit(trainDF)\n",
    "\n",
    "#test the model\n",
    "\n",
    "dt_predDF = pipelineModel_dt.transform(testDF)\n",
    " \n",
    "# Using areaUnderROC and areadUnderPR to evaluate binary classification model. roc is default measurement\n",
    "\n",
    "evaluator_roc = BinaryClassificationEvaluator()\n",
    "\n",
    "evaluator_pr=BinaryClassificationEvaluator(metricName=\"areaUnderPR\")\n",
    "\n",
    "# Evaluate logistic regression model \n",
    "\n",
    "print(\"Decision Tree areaUnderROC \", evaluator_roc.evaluate(dt_predDF))\n",
    "\n",
    "print(\"Deccision Tree areaUnderPR \", evaluator_pr.evaluate(dt_predDF))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "3e3690ce-53ac-472f-8b98-57ed11ebfaa9",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DecisionTreeClassificationModel: uid=DecisionTreeClassifier_9e51ebc5e537, depth=5, numNodes=23, numClasses=2, numFeatures=8\n"
     ]
    }
   ],
   "source": [
    "treeModel = pipelineModel_dt.stages[-1]\n",
    "# summary only\n",
    "print(treeModel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "e3ad7826-7007-47fd-80b2-19fac9744153",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix\n",
      " [[ 72   2]\n",
      " [  5 147]]\n",
      "\n",
      "Classification Report\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.97      0.95        74\n",
      "           1       0.99      0.97      0.98       152\n",
      "\n",
      "    accuracy                           0.97       226\n",
      "   macro avg       0.96      0.97      0.97       226\n",
      "weighted avg       0.97      0.97      0.97       226\n",
      "\n"
     ]
    }
   ],
   "source": [
    "classification_performance(dt_predDF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "40c933ad-c54b-4922-951d-35f15e1b64b4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# check feature importance for the tree baded model without ohe\n",
    "def dt_featureImportance_no_ohe(model, vecAssembler):\n",
    "    featureImp = pd.DataFrame(\n",
    "        list(zip(vecAssembler.getInputCols(), model.featureImportances)),\n",
    "      columns=[\"feature\", \"importance\"])\n",
    "    return featureImp.sort_values(by=\"importance\", ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "30fd9c8b-f192-4d42-a15a-82ffc3c90d08",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature</th>\n",
       "      <th>importance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>troponin</td>\n",
       "      <td>0.616069</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>kcm</td>\n",
       "      <td>0.353566</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>gender</td>\n",
       "      <td>0.021114</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>age</td>\n",
       "      <td>0.005510</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>pressurehight</td>\n",
       "      <td>0.003741</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>impluse</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>pressurelow</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>glucose</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         feature  importance\n",
       "7       troponin    0.616069\n",
       "6            kcm    0.353566\n",
       "1         gender    0.021114\n",
       "0            age    0.005510\n",
       "3  pressurehight    0.003741\n",
       "2        impluse    0.000000\n",
       "4    pressurelow    0.000000\n",
       "5        glucose    0.000000"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dtModel=pipelineModel_dt.stages[1]\n",
    "vecAssembler=pipelineModel_dt.stages[0]\n",
    "\n",
    "dt_featureImportance_no_ohe(dtModel, vecAssembler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b41f742-11eb-4661-9555-883792e04e7e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "BigDataEnv",
   "language": "python",
   "name": "bigdataenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
